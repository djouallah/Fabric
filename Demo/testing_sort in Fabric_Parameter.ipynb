{"cells":[{"cell_type":"markdown","source":["# Define Size"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["import random\r\n","sf= 100\r\n","#sf = random.randrange(1, 10)*10"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"56c14dbb-fbb8-45a9-8ec4-be1701222dc4","statement_id":3,"state":"finished","livy_statement_state":"available","queued_time":"2023-06-19T03:31:33.0807731Z","session_start_time":"2023-06-19T03:31:33.904592Z","execution_start_time":"2023-06-19T03:34:01.2554688Z","execution_finish_time":"2023-06-19T03:34:03.6431246Z","spark_jobs":{"numbers":{"RUNNING":0,"SUCCEEDED":0,"FAILED":0,"UNKNOWN":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"87a673f9-345d-491d-9293-044376cecfb4"},"text/plain":"StatementMeta(, 56c14dbb-fbb8-45a9-8ec4-be1701222dc4, 3, Finished, Available)"},"metadata":{}}],"execution_count":1,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"tags":["parameters"]}},{"cell_type":"code","source":["from psutil import *\n","core= cpu_count()\n","vCPU = str(core) + \" vCPU\"\n","mem=round(virtual_memory().total/(1024 * 1024 * 1024),0)\n","runtime = 'Sorting Lineitem-SF'+str(sf)+' ,Fabric Notebook, '+vCPU+' '+str(mem)+'GB'\n","runtime"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"56c14dbb-fbb8-45a9-8ec4-be1701222dc4","statement_id":4,"state":"finished","livy_statement_state":"available","queued_time":"2023-06-19T03:31:33.0813381Z","session_start_time":null,"execution_start_time":"2023-06-19T03:34:04.0880196Z","execution_finish_time":"2023-06-19T03:34:04.4294117Z","spark_jobs":{"numbers":{"RUNNING":0,"SUCCEEDED":0,"FAILED":0,"UNKNOWN":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"2959ff50-23d4-4d4c-882a-18b2424a6c1a"},"text/plain":"StatementMeta(, 56c14dbb-fbb8-45a9-8ec4-be1701222dc4, 4, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"'Sorting Lineitem-SF100 ,Fabric Notebook, 64 vCPU 504.0GB'"},"metadata":{}}],"execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"XZag4ZSSXUqw","outputId":"616a912d-a277-482b-ecb1-17e2a6f85a7a"}},{"cell_type":"markdown","source":["# Install Packages"],"metadata":{"id":"XwpvNhRHBWQf"}},{"cell_type":"code","source":["!pip install duckdb --pre --upgrade            "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"56c14dbb-fbb8-45a9-8ec4-be1701222dc4","statement_id":5,"state":"finished","livy_statement_state":"available","queued_time":"2023-06-19T03:31:33.0817899Z","session_start_time":null,"execution_start_time":"2023-06-19T03:34:04.7636396Z","execution_finish_time":"2023-06-19T03:34:15.3126662Z","spark_jobs":{"numbers":{"RUNNING":0,"SUCCEEDED":0,"FAILED":0,"UNKNOWN":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"a2f7d409-db7d-4f42-98ea-354c4f841032"},"text/plain":"StatementMeta(, 56c14dbb-fbb8-45a9-8ec4-be1701222dc4, 5, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting duckdb\n  Downloading duckdb-0.8.2.dev33-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m131.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: duckdb\nSuccessfully installed duckdb-0.8.2.dev33\n"]}],"execution_count":3,"metadata":{"id":"zp9radlkeSGP"}},{"cell_type":"code","source":["%%time\r\n","import duckdb\r\n","import pathlib\r\n","import os\r\n","import pandas as pd\r\n","import time\r\n","from datetime import datetime\r\n","if not os.path.isdir(f'/lakehouse/default/Files/{sf}'):\r\n","    for x in range(0, sf) :\r\n","        con=duckdb.connect()\r\n","        con.sql('PRAGMA disable_progress_bar;SET preserve_insertion_order=false')\r\n","        con.sql(f\"CALL dbgen(sf={sf} , children ={sf}, step = {x})\") \r\n","        for tbl in ['lineitem'] :\r\n","            pathlib.Path(f'/lakehouse/default/Files/{sf}/{tbl}').mkdir(parents=True, exist_ok=True) \r\n","            con.sql(f\"COPY (SELECT * FROM {tbl}) TO '/lakehouse/default/Files/{sf}/{tbl}/{x:03d}.parquet' \")\r\n","        con.close()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"56c14dbb-fbb8-45a9-8ec4-be1701222dc4","statement_id":6,"state":"finished","livy_statement_state":"available","queued_time":"2023-06-19T03:31:33.0824951Z","session_start_time":null,"execution_start_time":"2023-06-19T03:34:15.6935852Z","execution_finish_time":"2023-06-19T03:34:28.2352707Z","spark_jobs":{"numbers":{"RUNNING":0,"SUCCEEDED":0,"FAILED":0,"UNKNOWN":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"a0d34f99-550c-4ebb-82d3-8f99a85141b0"},"text/plain":"StatementMeta(, 56c14dbb-fbb8-45a9-8ec4-be1701222dc4, 6, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["CPU times: user 633 ms, sys: 96.3 ms, total: 730 ms\nWall time: 12 s\n"]}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["import os\r\n","mypath = f\"/lakehouse/default/Files/{sf}/Sort/\"\r\n","os.makedirs(mypath, exist_ok=True)\r\n","for root, dirs, files in os.walk(mypath, topdown=False):\r\n","    for file in files:\r\n","        os.remove(os.path.join(root, file))\r\n","\r\n","    # Add this block to remove folders\r\n","    for dir in dirs:\r\n","        os.rmdir(os.path.join(root, dir))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"56c14dbb-fbb8-45a9-8ec4-be1701222dc4","statement_id":7,"state":"finished","livy_statement_state":"available","queued_time":"2023-06-19T03:31:33.0830947Z","session_start_time":null,"execution_start_time":"2023-06-19T03:34:28.5513358Z","execution_finish_time":"2023-06-19T03:34:33.6162572Z","spark_jobs":{"numbers":{"RUNNING":0,"SUCCEEDED":0,"FAILED":0,"UNKNOWN":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"7b6c5524-8ecb-4c93-a921-267f9dc1a31f"},"text/plain":"StatementMeta(, 56c14dbb-fbb8-45a9-8ec4-be1701222dc4, 7, Finished, Available)"},"metadata":{}}],"execution_count":5,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["# DuckDB"],"metadata":{"id":"yqhDecjmncVE"}},{"cell_type":"code","source":["%%time\n","start = time.time()\n","import duckdb\n","con=duckdb.connect()\n","con.sql(\n","f'''\n","PRAGMA disable_progress_bar;\n","COPY  (select * from '/lakehouse/default/Files/{sf}/lineitem/*.parquet' order by l_shipdate )\n","to '/lakehouse/default/Files/{sf}/Sort/lineitem_DuckDB_Sort' (FORMAT 'PARQUET', PER_THREAD_OUTPUT TRUE)\n","''')\n","con.close()\n","duckdb_duration = time.time()-start\n","df = pd.DataFrame([{'engine':'DuckDB', 'value':duckdb_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\n","sparkDf = spark.createDataFrame(df);\n","sparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"56c14dbb-fbb8-45a9-8ec4-be1701222dc4","statement_id":8,"state":"finished","livy_statement_state":"available","queued_time":"2023-06-19T03:31:33.0842112Z","session_start_time":null,"execution_start_time":"2023-06-19T03:34:34.0369497Z","execution_finish_time":"2023-06-19T03:39:43.6468993Z","spark_jobs":{"numbers":{"RUNNING":0,"SUCCEEDED":7,"FAILED":0,"UNKNOWN":0},"jobs":[{"dataWritten":0,"dataRead":5070,"rowCount":50,"jobId":13,"name":"toString at String.java:2994","description":"Delta: Job group for statement 8:\n%%time\nstart = time.time()\nimport duckdb\ncon=duckdb.connect()\ncon.sql(\nf'''\nPRAGMA disable_progress_bar;\nCOPY  (select * from '/lakehouse/default/Files/{sf}/lineitem/*.parquet' order by l_shipdate )\nto '/lakehouse/default/Files/{sf}/Sort/lineitem_DuckDB_Sort' (FORMAT 'PARQUET', PER_THREAD_OUTPUT TRUE)\n''')\ncon.close()\nduckdb_duration = time.time()-start\ndf = pd.DataFrame([{'engine':'DuckDB', 'value':duckdb_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\nsparkDf = spark.createDataFrame(df);\nsparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\"): Compute snapshot for version: 761","submissionTime":"2023-06-19T03:39:42.547GMT","completionTime":"2023-06-19T03:39:42.578GMT","stageIds":[20,21,22],"jobGroup":"8","status":"SUCCEEDED","numTasks":53,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":52,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"dataWritten":5070,"dataRead":111136,"rowCount":810,"jobId":12,"name":"toString at String.java:2994","description":"Delta: Job group for statement 8:\n%%time\nstart = time.time()\nimport duckdb\ncon=duckdb.connect()\ncon.sql(\nf'''\nPRAGMA disable_progress_bar;\nCOPY  (select * from '/lakehouse/default/Files/{sf}/lineitem/*.parquet' order by l_shipdate )\nto '/lakehouse/default/Files/{sf}/Sort/lineitem_DuckDB_Sort' (FORMAT 'PARQUET', PER_THREAD_OUTPUT TRUE)\n''')\ncon.close()\nduckdb_duration = time.time()-start\ndf = pd.DataFrame([{'engine':'DuckDB', 'value':duckdb_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\nsparkDf = spark.createDataFrame(df);\nsparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\"): Compute snapshot for version: 761","submissionTime":"2023-06-19T03:39:42.013GMT","completionTime":"2023-06-19T03:39:42.527GMT","stageIds":[19,18],"jobGroup":"8","status":"SUCCEEDED","numTasks":52,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":2,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"dataWritten":111136,"dataRead":87394,"rowCount":1520,"jobId":11,"name":"toString at String.java:2994","description":"Delta: Job group for statement 8:\n%%time\nstart = time.time()\nimport duckdb\ncon=duckdb.connect()\ncon.sql(\nf'''\nPRAGMA disable_progress_bar;\nCOPY  (select * from '/lakehouse/default/Files/{sf}/lineitem/*.parquet' order by l_shipdate )\nto '/lakehouse/default/Files/{sf}/Sort/lineitem_DuckDB_Sort' (FORMAT 'PARQUET', PER_THREAD_OUTPUT TRUE)\n''')\ncon.close()\nduckdb_duration = time.time()-start\ndf = pd.DataFrame([{'engine':'DuckDB', 'value':duckdb_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\nsparkDf = spark.createDataFrame(df);\nsparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\"): Compute snapshot for version: 761","submissionTime":"2023-06-19T03:39:41.736GMT","completionTime":"2023-06-19T03:39:41.884GMT","stageIds":[17],"jobGroup":"8","status":"SUCCEEDED","numTasks":2,"numActiveTasks":0,"numCompletedTasks":2,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":2,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"dataWritten":2557,"dataRead":0,"rowCount":1,"jobId":10,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 8:\n%%time\nstart = time.time()\nimport duckdb\ncon=duckdb.connect()\ncon.sql(\nf'''\nPRAGMA disable_progress_bar;\nCOPY  (select * from '/lakehouse/default/Files/{sf}/lineitem/*.parquet' order by l_shipdate )\nto '/lakehouse/default/Files/{sf}/Sort/lineitem_DuckDB_Sort' (FORMAT 'PARQUET', PER_THREAD_OUTPUT TRUE)\n''')\ncon.close()\nduckdb_duration = time.time()-start\ndf = pd.DataFrame([{'engine':'DuckDB', 'value':duckdb_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\nsparkDf = spark.createDataFrame(df);\nsparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\")","submissionTime":"2023-06-19T03:39:40.579GMT","completionTime":"2023-06-19T03:39:41.078GMT","stageIds":[16],"jobGroup":"8","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"dataWritten":0,"dataRead":5070,"rowCount":50,"jobId":9,"name":"toString at String.java:2994","description":"Delta: Job group for statement 8:\n%%time\nstart = time.time()\nimport duckdb\ncon=duckdb.connect()\ncon.sql(\nf'''\nPRAGMA disable_progress_bar;\nCOPY  (select * from '/lakehouse/default/Files/{sf}/lineitem/*.parquet' order by l_shipdate )\nto '/lakehouse/default/Files/{sf}/Sort/lineitem_DuckDB_Sort' (FORMAT 'PARQUET', PER_THREAD_OUTPUT TRUE)\n''')\ncon.close()\nduckdb_duration = time.time()-start\ndf = pd.DataFrame([{'engine':'DuckDB', 'value':duckdb_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\nsparkDf = spark.createDataFrame(df);\nsparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\"): Compute snapshot for version: 760","submissionTime":"2023-06-19T03:39:40.060GMT","completionTime":"2023-06-19T03:39:40.328GMT","stageIds":[15,13,14],"jobGroup":"8","status":"SUCCEEDED","numTasks":52,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":51,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"dataWritten":5070,"dataRead":109914,"rowCount":808,"jobId":8,"name":"toString at String.java:2994","description":"Delta: Job group for statement 8:\n%%time\nstart = time.time()\nimport duckdb\ncon=duckdb.connect()\ncon.sql(\nf'''\nPRAGMA disable_progress_bar;\nCOPY  (select * from '/lakehouse/default/Files/{sf}/lineitem/*.parquet' order by l_shipdate )\nto '/lakehouse/default/Files/{sf}/Sort/lineitem_DuckDB_Sort' (FORMAT 'PARQUET', PER_THREAD_OUTPUT TRUE)\n''')\ncon.close()\nduckdb_duration = time.time()-start\ndf = pd.DataFrame([{'engine':'DuckDB', 'value':duckdb_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\nsparkDf = spark.createDataFrame(df);\nsparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\"): Compute snapshot for version: 760","submissionTime":"2023-06-19T03:39:39.389GMT","completionTime":"2023-06-19T03:39:40.036GMT","stageIds":[12,11],"jobGroup":"8","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"dataWritten":109914,"dataRead":97032,"rowCount":1516,"jobId":7,"name":"toString at String.java:2994","description":"Delta: Job group for statement 8:\n%%time\nstart = time.time()\nimport duckdb\ncon=duckdb.connect()\ncon.sql(\nf'''\nPRAGMA disable_progress_bar;\nCOPY  (select * from '/lakehouse/default/Files/{sf}/lineitem/*.parquet' order by l_shipdate )\nto '/lakehouse/default/Files/{sf}/Sort/lineitem_DuckDB_Sort' (FORMAT 'PARQUET', PER_THREAD_OUTPUT TRUE)\n''')\ncon.close()\nduckdb_duration = time.time()-start\ndf = pd.DataFrame([{'engine':'DuckDB', 'value':duckdb_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\nsparkDf = spark.createDataFrame(df);\nsparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\"): Compute snapshot for version: 760","submissionTime":"2023-06-19T03:39:37.645GMT","completionTime":"2023-06-19T03:39:39.255GMT","stageIds":[10],"jobGroup":"8","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"5f4da8f8-620b-485a-b61c-50dbe24a99cc"},"text/plain":"StatementMeta(, 56c14dbb-fbb8-45a9-8ec4-be1701222dc4, 8, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:604: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n"]},{"output_type":"stream","name":"stdout","text":["CPU times: user 40min 4s, sys: 1h 45min, total: 2h 25min 4s\nWall time: 5min 8s\n"]}],"execution_count":6,"metadata":{"id":"0HK-TCztkYmr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"578af9b5-cd83-4d4a-e1d9-f119fc37712d"}},{"cell_type":"markdown","source":["# Spark"],"metadata":{"id":"N7ecHVITNr4F"}},{"cell_type":"code","source":["%%time\n","import time\n","start = time.time()\n","df = spark.read.parquet(f\"Files/{sf}/lineitem/*.parquet\")\n","df.orderBy(\"l_shipdate\")\n","df.write.mode(\"overwrite\").format(\"parquet\").save(f\"Files/{sf}/Sort/Lineitem_Spark_Sort\")\n","Spark_duration = time.time()-start\n","df = pd.DataFrame([{'engine':'Spark', 'value':Spark_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\n","sparkDf = spark.createDataFrame(df);\n","sparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"56c14dbb-fbb8-45a9-8ec4-be1701222dc4","statement_id":9,"state":"finished","livy_statement_state":"available","queued_time":"2023-06-19T03:31:33.0848601Z","session_start_time":null,"execution_start_time":"2023-06-19T03:39:44.0746461Z","execution_finish_time":"2023-06-19T03:41:51.6694169Z","spark_jobs":{"numbers":{"RUNNING":0,"SUCCEEDED":7,"FAILED":0,"UNKNOWN":0},"jobs":[{"dataWritten":0,"dataRead":5062,"rowCount":50,"jobId":20,"name":"toString at String.java:2994","description":"Delta: Job group for statement 9:\n%%time\nimport time\nstart = time.time()\ndf = spark.read.parquet(f\"Files/{sf}/lineitem/*.parquet\")\ndf.orderBy(\"l_shipdate\")\ndf.write.mode(\"overwrite\").format(\"parquet\").save(f\"Files/{sf}/Sort/Lineitem_Spark_Sort\")\nSpark_duration = time.time()-start\ndf = pd.DataFrame([{'engine':'Spark', 'value':Spark_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\nsparkDf = spark.createDataFrame(df);\nsparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\"): Compute snapshot for version: 762","submissionTime":"2023-06-19T03:41:49.789GMT","completionTime":"2023-06-19T03:41:49.827GMT","stageIds":[30,31,32],"jobGroup":"9","status":"SUCCEEDED","numTasks":54,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":53,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"dataWritten":5062,"dataRead":112361,"rowCount":812,"jobId":19,"name":"toString at String.java:2994","description":"Delta: Job group for statement 9:\n%%time\nimport time\nstart = time.time()\ndf = spark.read.parquet(f\"Files/{sf}/lineitem/*.parquet\")\ndf.orderBy(\"l_shipdate\")\ndf.write.mode(\"overwrite\").format(\"parquet\").save(f\"Files/{sf}/Sort/Lineitem_Spark_Sort\")\nSpark_duration = time.time()-start\ndf = pd.DataFrame([{'engine':'Spark', 'value':Spark_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\nsparkDf = spark.createDataFrame(df);\nsparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\"): Compute snapshot for version: 762","submissionTime":"2023-06-19T03:41:49.619GMT","completionTime":"2023-06-19T03:41:49.771GMT","stageIds":[28,29],"jobGroup":"9","status":"SUCCEEDED","numTasks":53,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":3,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"dataWritten":112361,"dataRead":88341,"rowCount":1524,"jobId":18,"name":"toString at String.java:2994","description":"Delta: Job group for statement 9:\n%%time\nimport time\nstart = time.time()\ndf = spark.read.parquet(f\"Files/{sf}/lineitem/*.parquet\")\ndf.orderBy(\"l_shipdate\")\ndf.write.mode(\"overwrite\").format(\"parquet\").save(f\"Files/{sf}/Sort/Lineitem_Spark_Sort\")\nSpark_duration = time.time()-start\ndf = pd.DataFrame([{'engine':'Spark', 'value':Spark_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\nsparkDf = spark.createDataFrame(df);\nsparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\"): Compute snapshot for version: 762","submissionTime":"2023-06-19T03:41:49.359GMT","completionTime":"2023-06-19T03:41:49.490GMT","stageIds":[27],"jobGroup":"9","status":"SUCCEEDED","numTasks":3,"numActiveTasks":0,"numCompletedTasks":3,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":3,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"dataWritten":2550,"dataRead":0,"rowCount":1,"jobId":17,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 9:\n%%time\nimport time\nstart = time.time()\ndf = spark.read.parquet(f\"Files/{sf}/lineitem/*.parquet\")\ndf.orderBy(\"l_shipdate\")\ndf.write.mode(\"overwrite\").format(\"parquet\").save(f\"Files/{sf}/Sort/Lineitem_Spark_Sort\")\nSpark_duration = time.time()-start\ndf = pd.DataFrame([{'engine':'Spark', 'value':Spark_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\nsparkDf = spark.createDataFrame(df);\nsparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\")","submissionTime":"2023-06-19T03:41:48.608GMT","completionTime":"2023-06-19T03:41:48.824GMT","stageIds":[26],"jobGroup":"9","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"dataWritten":23390528819,"dataRead":27141195412,"rowCount":1200075804,"jobId":16,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 9:\n%%time\nimport time\nstart = time.time()\ndf = spark.read.parquet(f\"Files/{sf}/lineitem/*.parquet\")\ndf.orderBy(\"l_shipdate\")\ndf.write.mode(\"overwrite\").format(\"parquet\").save(f\"Files/{sf}/Sort/Lineitem_Spark_Sort\")\nSpark_duration = time.time()-start\ndf = pd.DataFrame([{'engine':'Spark', 'value':Spark_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\nsparkDf = spark.createDataFrame(df);\nsparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\")","submissionTime":"2023-06-19T03:40:20.658GMT","completionTime":"2023-06-19T03:41:48.174GMT","stageIds":[25],"jobGroup":"9","status":"SUCCEEDED","numTasks":206,"numActiveTasks":0,"numCompletedTasks":206,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":206,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"dataWritten":0,"dataRead":0,"rowCount":0,"jobId":15,"name":"parquet at NativeMethodAccessorImpl.java:0","description":"Job group for statement 9:\n%%time\nimport time\nstart = time.time()\ndf = spark.read.parquet(f\"Files/{sf}/lineitem/*.parquet\")\ndf.orderBy(\"l_shipdate\")\ndf.write.mode(\"overwrite\").format(\"parquet\").save(f\"Files/{sf}/Sort/Lineitem_Spark_Sort\")\nSpark_duration = time.time()-start\ndf = pd.DataFrame([{'engine':'Spark', 'value':Spark_duration , 'time':datetime.now().strftime('%Y-%m-%d %H:%M:%S') , 'sf':sf ,'cpu':core }])\nsparkDf = spark.createDataFrame(df);\nsparkDf.write.mode(\"append\").format(\"delta\").save(\"Tables/sort_stats\")","submissionTime":"2023-06-19T03:40:20.261GMT","completionTime":"2023-06-19T03:40:20.430GMT","stageIds":[24],"jobGroup":"9","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"dataWritten":0,"dataRead":0,"rowCount":0,"jobId":14,"name":"parquet at NativeMethodAccessorImpl.java:0","description":"Listing leaf files and directories for 100 paths:<br/>abfss://17b12c5b-edd2-4d48-be12-6477d0ff0d91@onelake.dfs.fabric.microsoft.com/bd2a6118-c2a0-4d11-85a8-0e2898c7549c/Files/100/lineitem/000.parquet, ...","submissionTime":"2023-06-19T03:39:44.214GMT","completionTime":"2023-06-19T03:40:20.154GMT","stageIds":[23],"jobGroup":"9","status":"SUCCEEDED","numTasks":100,"numActiveTasks":0,"numCompletedTasks":100,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":100,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"b6858944-1792-4fe8-a108-815fb39de9e2"},"text/plain":"StatementMeta(, 56c14dbb-fbb8-45a9-8ec4-be1701222dc4, 9, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:604: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n"]},{"output_type":"stream","name":"stdout","text":["CPU times: user 41 ms, sys: 8.67 ms, total: 49.6 ms\nWall time: 2min 5s\n"]}],"execution_count":7,"metadata":{"id":"DsXvjuwRN0U2","advisor":{"adviceMetadata":"{\"artifactId\":\"7adf9da3-599a-43f0-9c65-e0c67d7ea199\",\"activityId\":\"56c14dbb-fbb8-45a9-8ec4-be1701222dc4\",\"applicationId\":\"application_1687145567981_0001\",\"jobGroupId\":\"9\",\"advices\":{\"warn\":1}}"}}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"widgets":{},"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}},"trident":{"lakehouse":{"default_lakehouse":"bd2a6118-c2a0-4d11-85a8-0e2898c7549c","known_lakehouses":[{"id":"ae4bae7b-ffe8-4416-a2c1-df3d95e95c46"},{"id":"5b0917e6-0e49-47e9-beec-9dca4dd5ae58"},{"id":"bd2a6118-c2a0-4d11-85a8-0e2898c7549c"},{"id":"4aa7af52-9aab-4d6a-80a5-d102dbe4731a"}],"default_lakehouse_name":"Benchmarks_sort","default_lakehouse_workspace_id":"17b12c5b-edd2-4d48-be12-6477d0ff0d91"}}},"nbformat":4,"nbformat_minor":0}